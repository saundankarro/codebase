create or replace stage external_stage
storge_integration=external_storage_integration
url='s3://my-bucket-170108'
file_format=demo_format;

select $1.$2 from @external_stage;

create or replace table demo_table_1
(
    Employee_id Number,
    Employee_name String
);

copy into demo_table_1
from @external_stage;
force=true; -- Forces the copy through
Purge=true; -- Purges the data after copying
On_error = 'Continue' --Skips only the bad record
On_error = 'Skip_file' -- Skips only the whole file
On_error = 'Abort' -- Abort the process


create or replace pipe first_pipe
auto_ingest=True
As
copy into demo_table_1
from @external_stage;

select * from demo_table_1
before (timestamp=> '2024-04-24 21:41:25.533 -0700'::timestamp_ltz);

select * from demo_table_1
AT (timestamp=> '2024-04-24 21:41:25.533 -0700'::timestamp_ltz);

select * from table
before (statement=> '<queryID>');

select * from table
AT(OFFSET=>-120);


Undrop table table_name;
Undrop database database_name;

-- Create Backup of Demo Table 1 by cloning Demo Table 1 before given timestamp
Create demo_table_1_bkp clone demo_table_1
before(Timestamp => '2024-04-28 05:27:04.824 -0700'::timestamp_ltz)


-- To share data

-- Account that will share the data
Create share share_Demo_1;
Grant usage on Database Demo to share share_Demo_1;
Grant usage on Schema Demo to share share_Demo_1;
Grant select on Table demo_table_1 to share share_Demo_1;
-- Adding Consumer Account
Alter share share_name add account=<organization.account.name>;


-- Account that will consume the data
Create Database database name from share
provider_account_organization_name.provider_account_name.share_Demo_1;



-- Create a table
create or replace table trips
(
    tripduration integer,
    starttime timestamp,
    stoptime timestamp,
    start_station_id integer,
    start_station_name string,
    start_station_longitude string,
    start_station_latitude string,
    end_station_id integer,
    end_station_name string,
    end_station_longitude string,
    end_station_latitude string,
    bikeid integer,
    membership_type string,
    usertype string,
    birth_year integer,
    gender integer
);


-- check contents
list @citibike_trips

truncate table trips;

// load the data
copy into trips from @citibike_trips
file_format=CSV;

// get some sample stats
select date_trunc('hour',starttime) as 'date',
count(*) as 'num_trips',
avg(tripduration)/60 as 'avg_duration_mins',
avg(haversine(start_station_latitude, start_station_longitude, end_station_latitude, end_station_longitude)) as 'avg_distance_km'
from trips
group by 1
order by 1;


// Which month is busiest?
select monthname(starttime) as "month",
count(*) as "num trips"
from trips
group by 1
order by 2 desc;

// create a clone
create clone trips_dev clone trips;

create database weather;

set role sysadmin;
use warehouse compute_wh;
use database weather;
use schema public;

// create a new table
create table json_weather_data(v_variant);


// create a new stage
create stage nyc_weather
url = 's3://snowflake-workshop-lab/weather-nyc';

list @nyc_weather